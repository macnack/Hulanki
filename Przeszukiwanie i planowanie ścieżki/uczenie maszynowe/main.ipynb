{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e943e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfcae4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_id_to_new_class_id = {0: 0,\n",
    "                            1: 0,\n",
    "                            2: 0,\n",
    "                            3: 0,\n",
    "                            4: 0,\n",
    "                            5: 0,\n",
    "                            6: -1,\n",
    "                            7: 0,\n",
    "                            8: 0,\n",
    "                            9: 0,\n",
    "                            10: 0,\n",
    "                            11: 1,\n",
    "                            12: -1,\n",
    "                            13: 1,\n",
    "                            14: 0,\n",
    "                            15: 0,\n",
    "                            16: 0,\n",
    "                            17: 0,\n",
    "                            18: 1,\n",
    "                            19: 1,\n",
    "                            20: 1,\n",
    "                            21: 1,\n",
    "                            22: 1,\n",
    "                            23: 1,\n",
    "                            24: 1,\n",
    "                            25: 1,\n",
    "                            26: 1,\n",
    "                            27: 1,\n",
    "                            28: 1,\n",
    "                            29: 1,\n",
    "                            30: 1,\n",
    "                            31: 1,\n",
    "                            32: -1,\n",
    "                            33: 2,\n",
    "                            34: 2,\n",
    "                            35: 2,\n",
    "                            36: 2,\n",
    "                            37: 2,\n",
    "                            38: 2,\n",
    "                            39: 2,\n",
    "                            40: 2,\n",
    "                            41: -1,\n",
    "                            42: -1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47692f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path, filename):\n",
    "    \"\"\"\n",
    "    Loads data from disk.\n",
    "    @param path: Path to dataset directory.\n",
    "    @param filename: Filename of csv file with information about samples.\n",
    "    @return: List of dictionaries, one for every sample, with entries \"image\" (np.array with image) and \"label\" (class_id).\n",
    "    \"\"\"\n",
    "    entry_list = pandas.read_csv(os.path.join(path, filename))\n",
    "\n",
    "    data = []\n",
    "    class_to_num = {}\n",
    "    for idx, entry in entry_list.iterrows():\n",
    "        class_id = class_id_to_new_class_id[entry['ClassId']]\n",
    "        image_path = entry['Path']\n",
    "\n",
    "        if class_id != -1:\n",
    "            image = cv2.imread(os.path.join(path, image_path))\n",
    "            data.append({'image': image, 'label': class_id})\n",
    "\n",
    "            if class_id not in class_to_num:\n",
    "                class_to_num[class_id] = 0\n",
    "            class_to_num[class_id] += 1\n",
    "    class_to_num = dict(sorted(class_to_num.items(), key=lambda item: item[0]))\n",
    "    print(class_to_num)\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2630b622",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_bovw(data):\n",
    "    \"\"\"\n",
    "    Learns BoVW dictionary and saves it as \"voc.npy\" file.\n",
    "    @param data: List of dictionaries, one for every sample, with entries \"image\" (np.array with image) and \"label\" (class_id).\n",
    "    @return: Nothing\n",
    "    \"\"\"\n",
    "    dict_size = 128\n",
    "    bow = cv2.BOWKMeansTrainer(dict_size)\n",
    "\n",
    "    sift = cv2.SIFT_create()\n",
    "    for sample in data:\n",
    "        kpts = sift.detect(sample['image'], None)\n",
    "        kpts, desc = sift.compute(sample['image'], kpts)\n",
    "\n",
    "        if desc is not None:\n",
    "            bow.add(desc)\n",
    "\n",
    "    vocabulary = bow.cluster()\n",
    "\n",
    "    np.save('voc.npy', vocabulary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e892889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(data):\n",
    "    \"\"\"\n",
    "    Extracts features for given data and saves it as \"desc\" entry.\n",
    "    @param data: List of dictionaries, one for every sample, with entries \"image\" (np.array with image) and \"label\" (class_id).\n",
    "    @return: Data with added descriptors for each sample.\n",
    "    \"\"\"\n",
    "    sift = cv2.SIFT_create()\n",
    "    flann = cv2.FlannBasedMatcher_create()\n",
    "    bow = cv2.BOWImgDescriptorExtractor(sift, flann)\n",
    "    vocabulary = np.load('voc.npy')\n",
    "    bow.setVocabulary(vocabulary)\n",
    "\n",
    "    for sample in data:\n",
    "        # compute descriptor and add it as \"desc\" entry in sample\n",
    "        # TODO PUT YOUR CODE HERE\n",
    "        kpts = sift.detect(sample['image'], None)\n",
    "        imgDes = bow.compute(sample['image'], kpts)\n",
    "        # sample.update({'desc': imgDes})\n",
    "        if imgDes is not None:\n",
    "            sample.update({'desc': imgDes})\n",
    "        else:\n",
    "            sample.update({'desc': np.zeros((1, 128))})\n",
    "        # ------------------\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d601c678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_grid(images, n_classes, grid_size, h, w):\n",
    "    \"\"\"\n",
    "    Draws images on a grid, with columns corresponding to classes.\n",
    "    @param images: Dictionary with images in a form of (class_id, list of np.array images).\n",
    "    @param n_classes: Number of classes.\n",
    "    @param grid_size: Number of samples per class.\n",
    "    @param h: Height in pixels.\n",
    "    @param w: Width in pixels.\n",
    "    @return: Rendered image\n",
    "    \"\"\"\n",
    "    image_all = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "    h_size = int(h / grid_size)\n",
    "    w_size = int(w / n_classes)\n",
    "\n",
    "    col = 0\n",
    "    for class_id, class_images in images.items():\n",
    "        for idx, cur_image in enumerate(class_images):\n",
    "            row = idx\n",
    "\n",
    "            if col < n_classes and row < grid_size:\n",
    "                image_resized = cv2.resize(cur_image, (w_size, h_size))\n",
    "                image_all[row * h_size: (row + 1) * h_size, col * w_size: (col + 1) * w_size, :] = image_resized\n",
    "\n",
    "        col += 1\n",
    "\n",
    "    return image_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a69157b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data):\n",
    "    \"\"\"\n",
    "    Evaluates results of classification.\n",
    "    @param data: List of dictionaries, one for every sample, with entries \"image\" (np.array with image), \"label\" (class_id),\n",
    "                    \"desc\" (np.array with descriptor), and \"label_pred\".\n",
    "    @return: Nothing.\n",
    "    \"\"\"\n",
    "    # evaluate classification results and print statistics\n",
    "    # TODO PUT YOUR CODE HERE\n",
    "    y_pred = []\n",
    "    y_real = []\n",
    "    for sample in data:\n",
    "        y_pred.append(sample['label_pred'])\n",
    "        y_real.append(sample['label'])\n",
    "\n",
    "    confusion = confusion_matrix(y_real, y_pred)\n",
    "    TPa, Eba, Eca, Eab, TPb, Ecb, Eac, Ebc, TPc = confusion.ravel()\n",
    "    print(confusion)\n",
    "    accuracy = 100 * (TPa + TPb + TPc )/ (TPa + Eba + Eca + Eab + TPb + Ecb + Eac + Ebc + TPc) \n",
    "    print(\"accuracy =\", round(accuracy,2) , \"%\")\n",
    "    # ------------------\n",
    "    # this function does not return anything\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f76680",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(data):\n",
    "    \"\"\"\n",
    "    Displays samples of correct and incorrect classification.\n",
    "    @param data: List of dictionaries, one for every sample, with entries \"image\" (np.array with image), \"label\" (class_id),\n",
    "                    \"desc\" (np.array with descriptor), and \"label_pred\".\n",
    "    @return: Nothing.\n",
    "    \"\"\"\n",
    "    n_classes = 3\n",
    "\n",
    "    corr = {}\n",
    "    incorr = {}\n",
    "\n",
    "    for idx, sample in enumerate(data):\n",
    "        if sample['desc'] is not None:\n",
    "            if sample['label_pred'] == sample['label']:\n",
    "                if sample['label_pred'] not in corr:\n",
    "                    corr[sample['label_pred']] = []\n",
    "                corr[sample['label_pred']].append(idx)\n",
    "            else:\n",
    "                if sample['label_pred'] not in incorr:\n",
    "                    incorr[sample['label_pred']] = []\n",
    "                incorr[sample['label_pred']].append(idx)\n",
    "\n",
    "            # print('ground truth = %s, predicted = %s' % (sample['label'], pred))\n",
    "            # cv2.imshow('image', sample['image'])\n",
    "            # cv2.waitKey()\n",
    "\n",
    "    grid_size = 8\n",
    "\n",
    "    # sort according to classes\n",
    "    corr = dict(sorted(corr.items(), key=lambda item: item[0]))\n",
    "    corr_disp = {}\n",
    "    for key, samples in corr.items():\n",
    "        idxs = random.sample(samples, grid_size)\n",
    "        corr_disp[key] = [data[idx]['image'] for idx in idxs]\n",
    "    # sort according to classes\n",
    "    incorr = dict(sorted(incorr.items(), key=lambda item: item[0]))\n",
    "    incorr_disp = {}\n",
    "    for key, samples in incorr.items():\n",
    "        idxs = random.sample(samples, grid_size)\n",
    "        incorr_disp[key] = [data[idx]['image'] for idx in idxs]\n",
    "\n",
    "    image_corr = draw_grid(corr_disp, n_classes, grid_size, 800, 600)\n",
    "    image_incorr = draw_grid(incorr_disp, n_classes, grid_size, 800, 600)\n",
    "\n",
    "    cv2.imshow('images correct', image_corr)\n",
    "    cv2.imshow('images incorrect', image_incorr)\n",
    "    cv2.waitKey()\n",
    "\n",
    "    # this function does not return anything\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d6e506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data):\n",
    "    \"\"\"\n",
    "    Trains Random Forest classifier.\n",
    "    @param data: List of dictionaries, one for every sample, with entries \"image\" (np.array with image), \"label\" (class_id),\n",
    "                    \"desc\" (np.array with descriptor).\n",
    "    @return: Trained model.\n",
    "    \"\"\"\n",
    "    # train random forest model and return it from function.\n",
    "    # TODO PUT YOUR CODE HERE\n",
    "    clf = RandomForestClassifier(128)\n",
    "    x_vector = []\n",
    "    x_matrix = np.empty((1,128))\n",
    "    y_vector = []\n",
    "    for sample in data:\n",
    "        y_vector.append(sample['label'])\n",
    "        x_matrix = np.vstack((x_matrix, sample['desc']))\n",
    "    clf.fit(x_matrix[1:], y_vector)\n",
    "    # ------------------\n",
    "\n",
    "    return clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf30601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(rf, data):\n",
    "    \"\"\"\n",
    "    Predicts labels given a model and saves them as \"label_pred\" (int) entry for each sample.\n",
    "    @param rf: Trained model.\n",
    "    @param data: List of dictionaries, one for every sample, with entries \"image\" (np.array with image), \"label\" (class_id),\n",
    "                    \"desc\" (np.array with descriptor).\n",
    "    @return: Data with added predicted labels for each sample.\n",
    "    \"\"\"\n",
    "    # perform prediction using trained model and add results as \"label_pred\" (int) entry in sample\n",
    "    # TODO PUT YOUR CODE HERE\n",
    "    for sample in data:\n",
    "        sample.update({'label_pred': rf.predict(sample['desc'])[0]})\n",
    "    # ------------------\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e31fcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = load_data('./', 'Train.csv')\n",
    "data_test = load_data('./', 'Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e608c2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('learning BoVW')\n",
    "if os.path.isfile('voc.npy'):\n",
    "    print('BoVW is already learned')\n",
    "else:\n",
    "    learn_bovw(data_train)\n",
    "print('extracting train features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef48e9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('extracting train features')\n",
    "data_train = extract_features(data_train)\n",
    "print('training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24ab808",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('training')\n",
    "rf = train(data_train)\n",
    "print('extracting test features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e818935b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('extracting test features')\n",
    "data_test = extract_features(data_test)\n",
    "print('testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f76fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('testing')\n",
    "data_test = predict(rf, data_test)\n",
    "print('evaluate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587b1a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('evaluate')\n",
    "evaluate(data_test)\n",
    "print('display')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1a4df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680d5591",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
