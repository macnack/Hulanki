{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c5a201b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e368012f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# translation of 43 classes to 3 classes:\n",
    "# 0 - prohibitory\n",
    "# 1 - warning\n",
    "# 2 - mandatory\n",
    "# -1 - not used\n",
    "class_id_to_new_class_id = {0: 0,\n",
    "                            1: 0,\n",
    "                            2: 0,\n",
    "                            3: 0,\n",
    "                            4: 0,\n",
    "                            5: 0,\n",
    "                            6: -1,\n",
    "                            7: 0,\n",
    "                            8: 0,\n",
    "                            9: 0,\n",
    "                            10: 0,\n",
    "                            11: 1,\n",
    "                            12: -1,\n",
    "                            13: 1,\n",
    "                            14: 0,\n",
    "                            15: 0,\n",
    "                            16: 0,\n",
    "                            17: 0,\n",
    "                            18: 1,\n",
    "                            19: 1,\n",
    "                            20: 1,\n",
    "                            21: 1,\n",
    "                            22: 1,\n",
    "                            23: 1,\n",
    "                            24: 1,\n",
    "                            25: 1,\n",
    "                            26: 1,\n",
    "                            27: 1,\n",
    "                            28: 1,\n",
    "                            29: 1,\n",
    "                            30: 1,\n",
    "                            31: 1,\n",
    "                            32: -1,\n",
    "                            33: 2,\n",
    "                            34: 2,\n",
    "                            35: 2,\n",
    "                            36: 2,\n",
    "                            37: 2,\n",
    "                            38: 2,\n",
    "                            39: 2,\n",
    "                            40: 2,\n",
    "                            41: -1,\n",
    "                            42: -1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b95c2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path, filename):\n",
    "    \"\"\"\n",
    "    Loads data from disk.\n",
    "    @param path: Path to dataset directory.\n",
    "    @param filename: Filename of csv file with information about samples.\n",
    "    @return: List of dictionaries, one for every sample, with entries \"image\" (np.array with image) and \"label\" (class_id).\n",
    "    \"\"\"\n",
    "    entry_list = pandas.read_csv(os.path.join(path, filename))\n",
    "\n",
    "    data = []\n",
    "    for idx, entry in entry_list.iterrows():\n",
    "        class_id = class_id_to_new_class_id[entry['ClassId']]\n",
    "        image_path = entry['Path']\n",
    "\n",
    "        if class_id != -1:\n",
    "            image = cv2.imread(os.path.join(path, image_path))\n",
    "            data.append({'image': image, 'label': class_id})\n",
    "\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70355a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_bovw(data):\n",
    "    \"\"\"\n",
    "    Learns BoVW dictionary and saves it as \"voc.npy\" file.\n",
    "    @param data: List of dictionaries, one for every sample, with entries \"image\" (np.array with image) and \"label\" (class_id).\n",
    "    @return: Nothing\n",
    "    \"\"\"\n",
    "    dict_size = 128\n",
    "    bow = cv2.BOWKMeansTrainer(dict_size)\n",
    "\n",
    "    sift = cv2.SIFT_create()\n",
    "    for sample in data:\n",
    "        kpts = sift.detect(sample['image'], None)\n",
    "        kpts, desc = sift.compute(sample['image'], kpts)\n",
    "\n",
    "        if desc is not None:\n",
    "            bow.add(desc)\n",
    "\n",
    "    vocabulary = bow.cluster()\n",
    "\n",
    "    np.save('voc.npy', vocabulary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bc7b848",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(data):\n",
    "    \"\"\"\n",
    "    Extracts features for given data and saves it as \"desc\" entry.\n",
    "    @param data: List of dictionaries, one for every sample, with entries \"image\" (np.array with image) and \"label\" (class_id).\n",
    "    @return: Data with added descriptors for each sample.\n",
    "    \"\"\"\n",
    "    sift = cv2.SIFT_create()\n",
    "    flann = cv2.FlannBasedMatcher_create()\n",
    "    bow = cv2.BOWImgDescriptorExtractor(sift, flann)\n",
    "    vocabulary = np.load('voc.npy')\n",
    "    bow.setVocabulary(vocabulary)\n",
    "\n",
    "    for sample in data:\n",
    "        # compute descriptor and add it as \"desc\" entry in sample\n",
    "        # TODO PUT YOUR CODE HERE\n",
    "        kpts = sift.detect(sample['image'], None)\n",
    "        imgDes = bow.compute(sample['image'], kpts)\n",
    "        if imgDes is not None:\n",
    "            sample.update({'desc': imgDes})\n",
    "        else:\n",
    "            sample.update({'desc': np.zeros((1, 128))})\n",
    "        # ------------------\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b128df6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data):\n",
    "    \"\"\"\n",
    "    Trains Random Forest classifier.\n",
    "    @param data: List of dictionaries, one for every sample, with entries \"image\" (np.array with image), \"label\" (class_id),\n",
    "                    \"desc\" (np.array with descriptor).\n",
    "    @return: Trained model.\n",
    "    \"\"\"\n",
    "    # train random forest model and return it from function.\n",
    "    # TODO PUT YOUR CODE HERE\n",
    "    clf = RandomForestClassifier(300)\n",
    "    x_matrix = np.empty((1, 128))\n",
    "    y_vector = []\n",
    "    for sample in data:\n",
    "        y_vector.append(sample['label'])\n",
    "        x_matrix = np.vstack((x_matrix, sample['desc']))\n",
    "    clf.fit(x_matrix[1:], y_vector)\n",
    "    # ------------------\n",
    "\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61b7d9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_grid(images, n_classes, grid_size, h, w):\n",
    "    \"\"\"\n",
    "    Draws images on a grid, with columns corresponding to classes.\n",
    "    @param images: Dictionary with images in a form of (class_id, list of np.array images).\n",
    "    @param n_classes: Number of classes.\n",
    "    @param grid_size: Number of samples per class.\n",
    "    @param h: Height in pixels.\n",
    "    @param w: Width in pixels.\n",
    "    @return: Rendered image\n",
    "    \"\"\"\n",
    "    image_all = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "    h_size = int(h / grid_size)\n",
    "    w_size = int(w / n_classes)\n",
    "\n",
    "    col = 0\n",
    "    for class_id, class_images in images.items():\n",
    "        for idx, cur_image in enumerate(class_images):\n",
    "            row = idx\n",
    "\n",
    "            if col < n_classes and row < grid_size:\n",
    "                image_resized = cv2.resize(cur_image, (w_size, h_size))\n",
    "                image_all[row * h_size: (row + 1) * h_size, col * w_size: (col + 1) * w_size, :] = image_resized\n",
    "\n",
    "        col += 1\n",
    "\n",
    "    return image_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65cd88fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(rf, data):\n",
    "    \"\"\"\n",
    "    Predicts labels given a model and saves them as \"label_pred\" (int) entry for each sample.\n",
    "    @param rf: Trained model.\n",
    "    @param data: List of dictionaries, one for every sample, with entries \"image\" (np.array with image), \"label\" (class_id),\n",
    "                    \"desc\" (np.array with descriptor).\n",
    "    @return: Data with added predicted labels for each sample.\n",
    "    \"\"\"\n",
    "    # perform prediction using trained model and add results as \"label_pred\" (int) entry in sample\n",
    "    # TODO PUT YOUR CODE HERE\n",
    "    for sample in data:\n",
    "        sample.update({'label_pred': rf.predict(sample['desc'])[0]})\n",
    "    # ------------------\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73751a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data):\n",
    "    \"\"\"\n",
    "    Evaluates results of classification.\n",
    "    @param data: List of dictionaries, one for every sample, with entries \"image\" (np.array with image), \"label\" (class_id),\n",
    "                    \"desc\" (np.array with descriptor), and \"label_pred\".\n",
    "    @return: Nothing.\n",
    "    \"\"\"\n",
    "    # evaluate classification results and print statistics\n",
    "    # TODO PUT YOUR CODE HERE\n",
    "    y_pred = []\n",
    "    y_real = []\n",
    "    for sample in data:\n",
    "        y_pred.append(sample['label_pred'])\n",
    "        y_real.append(sample['label'])\n",
    "\n",
    "    confusion = confusion_matrix(y_real, y_pred)\n",
    "    _TPa, _Eba, _Eca, _Eab, _TPb, _Ecb, _Eac, _Ebc, _TPc = confusion.ravel()\n",
    "    print(confusion)\n",
    "    accuracy = 100 * (_TPa + _TPb + _TPc) / (_TPa + _Eba + _Eca + _Eab + _TPb + _Ecb + _Eac + _Ebc + _TPc)\n",
    "    print(\"accuracy =\", round(accuracy, 2), \"%\")\n",
    "    # ------------------\n",
    "    # this function does not return anything\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd258d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(data):\n",
    "    \"\"\"\n",
    "    Displays samples of correct and incorrect classification.\n",
    "    @param data: List of dictionaries, one for every sample, with entries \"image\" (np.array with image), \"label\" (class_id),\n",
    "                    \"desc\" (np.array with descriptor), and \"label_pred\".\n",
    "    @return: Nothing.\n",
    "    \"\"\"\n",
    "    n_classes = 3\n",
    "\n",
    "    corr = {}\n",
    "    incorr = {}\n",
    "\n",
    "    for idx, sample in enumerate(data):\n",
    "        if sample['desc'] is not None:\n",
    "            if sample['label_pred'] == sample['label']:\n",
    "                if sample['label_pred'] not in corr:\n",
    "                    corr[sample['label_pred']] = []\n",
    "                corr[sample['label_pred']].append(idx)\n",
    "            else:\n",
    "                if sample['label_pred'] not in incorr:\n",
    "                    incorr[sample['label_pred']] = []\n",
    "                incorr[sample['label_pred']].append(idx)\n",
    "\n",
    "            # print('ground truth = %s, predicted = %s' % (sample['label'], pred))\n",
    "            # cv2.imshow('image', sample['image'])\n",
    "            # cv2.waitKey()\n",
    "\n",
    "    grid_size = 8\n",
    "\n",
    "    # sort according to classes\n",
    "    corr = dict(sorted(corr.items(), key=lambda item: item[0]))\n",
    "    corr_disp = {}\n",
    "    for key, samples in corr.items():\n",
    "        idxs = random.sample(samples, min(grid_size, len(samples)))\n",
    "        corr_disp[key] = [data[idx]['image'] for idx in idxs]\n",
    "    # sort according to classes\n",
    "    incorr = dict(sorted(incorr.items(), key=lambda item: item[0]))\n",
    "    incorr_disp = {}\n",
    "    for key, samples in incorr.items():\n",
    "        idxs = random.sample(samples, min(grid_size, len(samples)))\n",
    "        incorr_disp[key] = [data[idx]['image'] for idx in idxs]\n",
    "\n",
    "    image_corr = draw_grid(corr_disp, n_classes, grid_size, 800, 600)\n",
    "    image_incorr = draw_grid(incorr_disp, n_classes, grid_size, 800, 600)\n",
    "\n",
    "    cv2.imshow('images correct', image_corr)\n",
    "    cv2.imshow('images incorrect', image_incorr)\n",
    "    cv2.waitKey()\n",
    "\n",
    "    # this function does not return anything\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25d1a1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_dataset_stats(data):\n",
    "    \"\"\"\n",
    "    Displays statistics about dataset in a form: class_id: number_of_samples\n",
    "    @param data: List of dictionaries, one for every sample, with entry \"label\" (class_id).\n",
    "    @return: Nothing\n",
    "    \"\"\"\n",
    "    class_to_num = {}\n",
    "    for idx, sample in enumerate(data):\n",
    "        class_id = sample['label']\n",
    "        if class_id not in class_to_num:\n",
    "            class_to_num[class_id] = 0\n",
    "        class_to_num[class_id] += 1\n",
    "\n",
    "    class_to_num = dict(sorted(class_to_num.items(), key=lambda item: item[0]))\n",
    "    # print('number of samples for each class:')\n",
    "    print(class_to_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06426339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_dataset(data, ratio):\n",
    "    \"\"\"\n",
    "    Subsamples dataset according to ratio.\n",
    "    @param data: List of samples.\n",
    "    @param ratio: Ratio of samples to be returned.\n",
    "    @return: Subsampled dataset.\n",
    "    \"\"\"\n",
    "    sampled_data = random.sample(data, int(ratio * len(data)))\n",
    "    class_zero = 0 \n",
    "    class_two = 0\n",
    "    class_three = 0\n",
    "    class_zeros = []\n",
    "    class_twos = []\n",
    "    class_threes = []\n",
    "    for sample in data:\n",
    "        if( sample['label'] == 0):\n",
    "            class_zeros.append(sample)\n",
    "            class_zero += 1\n",
    "        if( sample['label'] == 1):\n",
    "            class_two += 1\n",
    "            class_twos.append(sample)\n",
    "        if( sample['label'] == 2):\n",
    "            class_three += 1\n",
    "            class_threes.append(sample)\n",
    "    find_min = [class_zero, class_two, class_three]\n",
    "    find_min = np.min(find_min)\n",
    "    sampled_data = []\n",
    "    class_zeros = random.sample(class_zeros, find_min)\n",
    "    class_twos = random.sample(class_twos, find_min)\n",
    "    class_threes = random.sample(class_threes, find_min)\n",
    "    for x in range(find_min):\n",
    "        sampled_data.append(class_zeros[x])\n",
    "        sampled_data.append(class_twos[x])\n",
    "        sampled_data.append(class_threes[x])\n",
    "    return sampled_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "748d8a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    data_train = load_data('./', 'Train.csv')\n",
    "    print('train dataset before balancing:')\n",
    "    display_dataset_stats(data_train)\n",
    "    data_train = balance_dataset(data_train, 1.0)\n",
    "    print('train dataset after balancing:')\n",
    "    display_dataset_stats(data_train)\n",
    "\n",
    "    data_test = load_data('./', 'Test.csv')\n",
    "    print('test dataset before balancing:')\n",
    "    display_dataset_stats(data_test)\n",
    "    data_test = balance_dataset(data_test, 1.0)\n",
    "    print('test dataset after balancing:')\n",
    "    display_dataset_stats(data_test)\n",
    "\n",
    "    # you can comment those lines after dictionary is learned and saved to disk.\n",
    "    print('learning BoVW')\n",
    "    if os.path.isfile('voc.npy'):\n",
    "        print('BoVW is already learned')\n",
    "    else:\n",
    "        learn_bovw(data_train)\n",
    "\n",
    "    print('extracting train features')\n",
    "    data_train = extract_features(data_train)\n",
    "\n",
    "    print('training')\n",
    "    rf = train(data_train)\n",
    "\n",
    "    print('extracting test features')\n",
    "    data_test = extract_features(data_test)\n",
    "\n",
    "    print('testing on testing dataset')\n",
    "    data_test = predict(rf, data_test)\n",
    "    evaluate(data_test)\n",
    "    display(data_test)\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "766f22c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cfba3eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset before balancing:\n",
      "{0: 19200, 1: 11130, 2: 5639}\n",
      "train dataset after balancing:\n",
      "{0: 19200, 1: 11130, 2: 5639}\n"
     ]
    }
   ],
   "source": [
    "data_train = load_data('./', 'Train.csv')\n",
    "print('train dataset before balancing:')\n",
    "display_dataset_stats(data_train)\n",
    "#data_train = balance_dataset(data_train, 1.0)\n",
    "print('train dataset after balancing:')\n",
    "display_dataset_stats(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1c4d2109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test dataset before balancing:\n",
      "{0: 6300, 1: 3510, 2: 1770}\n",
      "11580\n",
      "test dataset after balancing:\n",
      "{0: 1770, 1: 1770, 2: 1770}\n"
     ]
    }
   ],
   "source": [
    "data_test = load_data('./', 'Test.csv')\n",
    "print('test dataset before balancing:')\n",
    "display_dataset_stats(data_test)\n",
    "print(len(data_test))\n",
    "data_test = balance_dataset(data_test, 1.0)\n",
    "print('test dataset after balancing:')\n",
    "display_dataset_stats(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6916241d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning BoVW\n",
      "BoVW is already learned\n"
     ]
    }
   ],
   "source": [
    "print('learning BoVW')\n",
    "if os.path.isfile('voc.npy'):\n",
    "    print('BoVW is already learned')\n",
    "else:\n",
    "    learn_bovw(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "46b1085b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting train features\n",
      "training\n"
     ]
    }
   ],
   "source": [
    "print('extracting train features')\n",
    "data_train = extract_features(data_train)\n",
    "\n",
    "print('training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8c7fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n"
     ]
    }
   ],
   "source": [
    "print('training')\n",
    "rf = train(data_train)\n",
    "\n",
    "print('extracting test features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df61e755",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('extracting test features')\n",
    "data_test = extract_features(data_test)\n",
    "#data_test = data_train\n",
    "#data_test = extract_features(data_train)\n",
    "print('testing on testing dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b319fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = predict(rf, data_test)\n",
    "evaluate(data_test)\n",
    "#display(data_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
